"""
Interface Streamlit - Chat RAG pour DPO

Architecture clÃ© en main :
- Hybrid Search (BM25 + Semantic + RRF)
- Cross-Encoder Reranking
- Reverse Repacking
- Grounding Validation
"""
import streamlit as st
import sys
import logging
from pathlib import Path
from datetime import datetime

# Setup path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

import chromadb
from src.utils.llm_provider import OllamaProvider
from src.rag.pipeline import create_pipeline


# Configuration page
st.set_page_config(
    page_title="RAG-DPO Assistant",
    page_icon="ğŸ”’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Logging : on ne veut que les messages utiles
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
for noisy in ("httpx", "ollama", "chromadb", "sentence_transformers", "urllib3"):
    logging.getLogger(noisy).setLevel(logging.WARNING)
logger = logging.getLogger(__name__)


# â”€â”€ CSS â”€â”€
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .source-card {
        padding: 0.6rem 0.8rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        background-color: rgba(128, 128, 128, 0.1);
        margin: 0.3rem 0;
        color: inherit;
        font-size: 0.9rem;
    }
    .cited { border-left-color: #28a745; }
    .uncited { border-left-color: #6c757d; opacity: 0.7; }
    .metadata { font-size: 0.8rem; opacity: 0.8; }
    .source-card a { color: #4da6ff; }
    .msg-time {
        font-size: 0.75rem;
        opacity: 0.5;
        margin-bottom: 0.3rem;
    }
</style>
""", unsafe_allow_html=True)


# â”€â”€ Initialisation RAG (cachÃ©e) â”€â”€

@st.cache_resource
def init_rag_system():
    """Initialise le pipeline RAG complet â€” appelÃ© une seule fois."""
    try:
        vectordb_path = project_root / "data" / "vectordb" / "chromadb"
        if not vectordb_path.exists():
            st.error(f"âŒ VectorDB introuvable : {vectordb_path}")
            st.stop()

        client = chromadb.PersistentClient(path=str(vectordb_path))
        collection = client.get_collection("rag_dpo_chunks")

        llm_provider = OllamaProvider(
            base_url="http://localhost:11434",
            model="mistral-nemo"
        )

        pipeline = create_pipeline(
            collection=collection,
            llm_provider=llm_provider,
            # Retrieval
            n_documents=5,
            n_chunks_per_doc=3,
            # Architecture complÃ¨te â€” pas de toggle
            enable_hybrid=True,
            enable_reranker=True,
            enable_summary_prefilter=True,
            enable_validation=True,
            # GÃ©nÃ©ration
            model="mistral-nemo",
            temperature=0.0,
            debug_mode=False,
        )

        return pipeline, collection.count()

    except Exception as e:
        st.error(f"âŒ Erreur initialisation RAG : {e}")
        logger.error(f"Init error: {e}", exc_info=True)
        st.stop()


# â”€â”€ Carte source (inline dans le chat) â”€â”€

def render_source_card(source):
    """Retourne le HTML d'une carte source."""
    cited_class = "cited" if source['cited'] else "uncited"
    cited_icon = "âœ…" if source['cited'] else "ğŸ“„"

    url = source.get('url', source.get('path', ''))
    file_type = source.get('file_type', '')
    title = source.get('title', '')

    if url.startswith('http'):
        source_line = f'ğŸ”— <a href="{url}" target="_blank">{url[:80]}</a>'
    else:
        source_line = f'ğŸ“ {url}'

    type_badge = ''
    if file_type:
        type_badge = (
            f' <span style="background:rgba(128,128,128,0.2);padding:1px 6px;'
            f'border-radius:3px;font-size:0.8em">{file_type.upper()}</span>'
        )

    title_line = f'<br>ğŸ“ {title[:120]}' if title else ''

    locations = source.get('locations', [])
    location_line = ''
    if locations:
        location_line = '<br>ğŸ“ ' + ' | '.join(loc[:80] for loc in locations[:3])

    return f"""<div class="source-card {cited_class}">
        <strong>{cited_icon} Source {source['id']} - {source['nature']}{type_badge}</strong>
        <div class="metadata">
            {source_line}{title_line}{location_line}<br>
            ğŸ“Š Score : {source['score']:.3f}
        </div>
    </div>"""


def render_sources_block(sources):
    """Affiche les sources dans un expander sous la rÃ©ponse."""
    if not sources:
        return
    
    cited = [s for s in sources if s['cited']]
    uncited = [s for s in sources if not s['cited']]
    n_cited = len(cited)
    n_total = len(sources)
    
    with st.expander(f"ğŸ“š {n_cited}/{n_total} sources citÃ©es", expanded=False):
        # Sources citÃ©es d'abord
        for source in sorted(cited, key=lambda s: s['id']):
            st.markdown(render_source_card(source), unsafe_allow_html=True)
        # Sources non citÃ©es ensuite
        for source in sorted(uncited, key=lambda s: s['id']):
            st.markdown(render_source_card(source), unsafe_allow_html=True)


# â”€â”€ Application â”€â”€

def main():
    st.markdown('<div class="main-header">ğŸ”’ RAG-DPO Assistant</div>', unsafe_allow_html=True)
    st.markdown("---")

    # â”€â”€ Sidebar â”€â”€
    with st.sidebar:
        st.header("âš™ï¸ Configuration")

        # Filtres optionnels
        st.subheader("ğŸ” Filtres")
        filter_nature = st.multiselect(
            "Nature des documents",
            ["DOCTRINE", "GUIDE", "SANCTION", "TECHNIQUE"],
            default=[]
        )

        # Profondeur de recherche
        st.subheader("ğŸ“¥ Profondeur")
        depth = st.select_slider(
            "Ressources Ã  consulter",
            options=["Normal", "Approfondi", "Exhaustif"],
            value="Normal",
            help="Normal = 5 docs / Approfondi = 8 docs / Exhaustif = 12 docs"
        )

        st.markdown("---")

        # Nouvelle conversation
        if st.button("ğŸ”„ Nouvelle conversation", use_container_width=True):
            st.session_state.messages = []
            st.session_state.conversation_history = []
            st.rerun()

        # Stats
        st.markdown("---")
        if 'chunk_count' in st.session_state:
            st.metric("ğŸ“š Chunks indexÃ©s", f"{st.session_state.chunk_count:,}")
        if 'messages' in st.session_state:
            n_questions = sum(1 for m in st.session_state.messages if m['role'] == 'user')
            if n_questions:
                st.metric("ğŸ’¬ Questions posÃ©es", n_questions)

    # â”€â”€ ParamÃ¨tres dÃ©rivÃ©s du slider â”€â”€
    depth_config = {
        "Normal":     {"n_documents": 5,  "n_chunks_per_doc": 3},
        "Approfondi": {"n_documents": 8,  "n_chunks_per_doc": 4},
        "Exhaustif":  {"n_documents": 12, "n_chunks_per_doc": 5},
    }
    params = depth_config[depth]

    # â”€â”€ Init pipeline â”€â”€
    if 'pipeline' not in st.session_state:
        with st.spinner("ğŸš€ Initialisation du systÃ¨me RAG..."):
            pipeline, chunk_count = init_rag_system()
            st.session_state.pipeline = pipeline
            st.session_state.chunk_count = chunk_count

    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []

    # â”€â”€ Filtre ChromaDB â”€â”€
    where_filter = None
    if filter_nature:
        where_filter = {"chunk_nature": {"$in": filter_nature}}

    # â”€â”€ Affichage de l'historique â”€â”€
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Horodatage
            if "timestamp" in message:
                st.markdown(f'<div class="msg-time">{message["timestamp"]}</div>', unsafe_allow_html=True)
            # Contenu
            st.markdown(message["content"])
            # Sources (sous les rÃ©ponses assistant uniquement)
            if message["role"] == "assistant" and "sources" in message:
                render_sources_block(message["sources"])

    # â”€â”€ Saisie (pleine largeur, toujours en bas) â”€â”€
    if prompt := st.chat_input("Posez votre question sur le RGPD / la protection des donnÃ©es..."):
        now = datetime.now().strftime("%H:%M")

        # Message utilisateur
        with st.chat_message("user"):
            st.markdown(f'<div class="msg-time">{now}</div>', unsafe_allow_html=True)
            st.markdown(prompt)
        st.session_state.messages.append({
            "role": "user",
            "content": prompt,
            "timestamp": now,
        })

        # RÃ©ponse assistant
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” Recherche et analyse en cours..."):
                try:
                    response = st.session_state.pipeline.query(
                        question=prompt,
                        where_filter=where_filter,
                        conversation_history=st.session_state.conversation_history,
                        n_documents=params["n_documents"],
                        n_chunks_per_doc=params["n_chunks_per_doc"],
                    )

                    if response.error:
                        st.error(f"âŒ {response.error}")
                    else:
                        resp_time = datetime.now().strftime("%H:%M")
                        st.markdown(f'<div class="msg-time">{resp_time}</div>', unsafe_allow_html=True)
                        st.markdown(response.answer)

                        st.caption(
                            f"â±ï¸ {response.total_time:.1f}s "
                            f"| ğŸ“š {len(response.sources)} sources "
                            f"| âœ… {len(response.cited_sources)} citÃ©es"
                        )

                        # Sources inline sous la rÃ©ponse
                        render_sources_block(response.sources)

                        # Stocker message + sources pour le replay
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response.answer,
                            "timestamp": resp_time,
                            "sources": response.sources,
                        })
                        st.session_state.conversation_history.append({
                            "role": "user", "content": prompt
                        })
                        st.session_state.conversation_history.append({
                            "role": "assistant", "content": response.answer
                        })

                except Exception as e:
                    st.error(f"âŒ Erreur inattendue : {e}")
                    logger.error(f"Query error: {e}", exc_info=True)

    # Footer
    st.markdown("---")
    st.caption("ğŸ”’ RAG-DPO Assistant â€” Sources CNIL officielles â€” mistral-nemo 12B â€” 100% local")


if __name__ == "__main__":
    main()
