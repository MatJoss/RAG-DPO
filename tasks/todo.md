# Todo List - RAG-DPO System

**DerniÃ¨re MAJ** : 2026-02-11

---

## ğŸ”¬ DIAGNOSTIC RECHUNKING â€” Faits bruts (2026-02-11)

### Contexte
v5 (bge-reranker) = 91.2%. v6 (retrieve_candidates + reranker flow) â‰ˆ 87%.
Le pipeline tweaking (top_k, n_chunks_per_doc, etc.) ne rÃ©sout rien.
L'information est dans les chunks, mais elle est **mal dÃ©coupÃ©e et diluÃ©e**.

### Distribution actuelle (16,044 chunks)
```
Tiny(<50w):    441   (2.7%)  â† inutilisables, bruit
Small(50-150): 1754  (10.9%) â† trop courts, contexte perdu  
Medium(150-400):5499 (34.3%) â† acceptables mais souvent diluÃ©s
Target(400-600):8072 (50.3%) â† taille cible max_size=450 du chunker
Large(600+):    278  (1.7%)  â† dÃ©passent le max, split naÃ¯f par mots
```

### ProblÃ¨me 1 : Information DILUÃ‰E (q05, q08, q10, q11)
Les keywords manquants EXISTENT dans la base mais sont Ã©parpillÃ©s :
- q05 "donnÃ©es sensibles" + "grande Ã©chelle" : 38 chunks avec TOUT, mais 685 avec au moins 1 â†’ **5.5% concentration**
- q08 "portabilitÃ©" + "limitation" : 124/1119 = **11.1% concentration**
- q10 "mise en balance" + "sÃ©curitÃ©" : 17/3595 = **0.5% concentration**
- q11 "base lÃ©gale" + "contrat de travail" : 9/648 = **1.4% concentration**

â†’ Le chunker coupe au milieu des concepts. Un paragraphe qui parle de "donnÃ©es sensibles Ã  grande Ã©chelle" est splittÃ© en deux chunks de 400 mots.

### ProblÃ¨me 2 : Information ABSENTE du retrieval (q09)
- **1 SEUL** chunk contient "2 ans" + "dernier contact" (chunk #2319, 752w)
- MAIS c'est dans un document sur la **prospection commerciale** (d05ee50f6467), pas les CV
- Le vrai passage CV est chunk #18 (588w, doc 83e81e7846a8) : "*les donnÃ©es d'un candidat non retenu seront conservÃ©es pendant 2 ans maximum*"
- Ce chunk #18 parle de "2 ans" + "candidat" + "recrutement" mais PAS de "dernier contact"
- ProblÃ¨me : la query "conserver des CV indÃ©finiment" ne matche pas sÃ©mantiquement "candidat non retenu 2 ans maximum"
- Le keyword "CV" n'apparaÃ®t mÃªme pas dans le chunk â†’ BM25 rate aussi

### ProblÃ¨me 3 : Chunks SANS heading (perte de contexte)
- chunk #99 et #100 (07ec6ca4d34d.html) : 400w chacun, heading="" â†’ c'est le texte du RGPD splittÃ©
- chunk #2319 : heading="Comment assurer le respect du droit d'opposition..." â†’ misleading pour q09 CV
- Le chunker split par taille (max_size=450) et perd le contexte sectionnel

### ProblÃ¨me 4 : Split naÃ¯f des gros documents
- `_post_process()` dans process_and_chunk.py : si >450 mots, split par `text_words[i:i+target_size]`
- Pas d'overlap ! Un concept coupÃ© au milieu est irrÃ©mÃ©diablement perdu
- Pas de heading propagÃ© au chunk enfant

### ProblÃ¨me 5 : Le chunk #659 est PARFAIT mais le reranker ne le trouve pas toujours
- Chunk #659 (278w) : "Quand est-ce qu'une AIPD est obligatoire ?" avec les 9 critÃ¨res listÃ©s
- Ce chunk est la rÃ©ponse exacte Ã  q05 mais doit Ãªtre dans les 60 premiers candidats cosine
- Embeddings nomic-embed-text saturÃ©s â†’ cet excellent chunk se noie dans le cluster AIPD

---

## ğŸ—ï¸ PLAN RECHUNKING â€” 3 phases

### Phase R1 : Rechunking intelligent âœ… DONE
**Objectif** : Transformer 16,044 chunks de qualitÃ© inÃ©gale en chunks auto-suffisants.

**Changements au chunker** (`process_and_chunk.py`) :
- [x] **Overlap 50 mots** : `_split_semantic()` ajoute 50w du chunk prÃ©cÃ©dent
- [x] **Heading propagÃ©** : `_post_process()` stage 3 prÃ©fixe `[heading]` dans le texte
- [x] **Split sÃ©mantique** : coupe sur `\n\n` puis `. `, fallback mot
- [x] **Taille cible 400w** : target=400, min=100, max=600 (souple)
- [x] **Purge tiny chunks** : <100w fusionnÃ© avec voisin (stage 2)
- [x] **Heading dans le texte** : `[heading] text` pour que l'embedding le voie

**RÃ©sultat** : 16,044 â†’ **14,388 chunks** (-10.3%, moins de bruit)

### Phase R2 : Re-indexation ChromaDB âœ… DONE
- [x] Re-gÃ©nÃ©rÃ© `processed_chunks.jsonl` (14,388 chunks, 1832 docs)
- [x] Re-indexÃ© ChromaDB (mode reset, 3m31s)
- [x] VÃ©rifiÃ© : 100% indexÃ©s, filtre par nature OK

### Phase R3 : Ã‰valuation comparative âœ… DONE
- [x] Eval v7a (rechunking seul, Ã©val biaisÃ©e) : 89% global, 75% correctness
- [x] Diagnostic biais Ã©val : questions vagues â†” must_include trop spÃ©cifiques
- [x] Fix Ã©val : `must_include_any` (N parmi M) + alternates pipe-separated
- [x] Eval v7b (rechunking + fix Ã©val) : **93% global, 84% correctness** â† nouveau record

### Phase R4 : Retrieval restant (q09, q10)
- [ ] q09 (60%) : "2 ans" + "dernier contact" pour CV â€” vrai manque retrieval
- [ ] q10 (73%) : rÃ©ponse factuelle fausse (dit "non" au lieu de "oui, avec mise en balance")
- [ ] q06 (80%) : rÃ©ponse superficielle (pas de dÃ©tails liste noire/blanche)
- [ ] Objectif : â‰¥95% global, 0 question en dessous de 73%

### Hors scope (pour plus tard)
- Changer d'embeddings (e5-large, etc.) â€” gros chantier, pas la prioritÃ©
- BM25 avec stemming FR â€” amÃ©lioration marginale vs rechunking
- Fine-tuning embeddings â€” nÃ©cessite un dataset gold standard
- Augmentation query expansion â€” dÃ©jÃ  en place, amÃ©lioration marginale

---

## Ã‰TAT PIPELINE : Reconstruction (Nemo 12B + region-content)

### Phase 0 : Corrections Code âœ…
- [x] Fix extraction HTML: `region-content` dans tous les modules
- [x] ModÃ¨le migrÃ©: mistral-nemo partout
- [x] AmÃ©liorer prompts: toutes phases (3, 5A, 6B, RAG query)
- [x] Fix critique: process_and_chunk.py ignore les 49 docs (xlsx/odt/docx)
- [x] Fix critique: PDF chunking â†’ TOC/font/smart
- [x] RÃ©Ã©crire: rebuild_pipeline.py avec TOUTES les phases (3â†’6b)
- [x] Checkpoint/resume: hybrid_filter.py + process_and_chunk.py
- [x] Sanity checks post-phase dans rebuild_pipeline.py
- [x] Fix chemins cohÃ©rents data/raw/cnil/

### Phase 3 : Classification hybride âœ…
- [x] 8236 HTML â†’ 2568 keep (31.2%), 11.9h

### Phase 4 : Organisation keep/archive âœ…
- [x] 2568 HTML, 1026 PDFs, 43 docs, 221 images dans keep/

### Phase 4B : Classification images (OCR + LLaVA) âœ…
- [x] 221 images â†’ 65 SCHEMA_DPO keep, 156 PHOTO_DECO Ã©liminÃ©es
- [x] Fix: --test mode dry-run (pas de modification manifest)
- [x] Fix: stats comptent correctement les images cachÃ©es

### Phase 4C : DÃ©duplication corpus âœ…
- [x] CrÃ©Ã© `src/processing/deduplicate_corpus.py`
  - Hash MD5 region-content pour HTML, binaire pour PDF/docs/images
  - SÃ©lection canonical : https > http, URL la plus courte
  - Archivage dans keep/dedup_archive/ (pas de suppression)
  - Backup manifest automatique (.pre_dedup)
  - Support --fresh (restaure backup), --dry-run
- [x] IntÃ©grÃ© dans rebuild_pipeline.py (Phase 4C, sanity check)
- [x] **RÃ©sultat** : 3702 â†’ 1847 docs (-50.1%)
  - HTML: 2568 â†’ 1300 (-1268)
  - PDF: 1026 â†’ 485 (-541)
  - Docs: 43 â†’ 29 (-14)
  - Images: 65 â†’ 33 (-32)
- [x] 1855 fichiers archivÃ©s dans keep/dedup_archive/
- [x] keep/ vÃ©rifiÃ© = manifest exact
- [x] Fix --fresh : restaure backup manifest + ne l'Ã©crase pas

### Phase 5A : Classification documents (Nemo) âœ…
- [x] Code modifiÃ© : intÃ¨gre images SCHEMA_DPO (classification dÃ©terministe)
- [x] Fix json_cleaner : double braces `{{...}}` â†’ `{...}`
- [x] Fix manifest : 14 ODS avaient extension `.xlsx` â†’ corrigÃ©
- [x] Nettoyage rÃ©siduel : 11 ODS dupliquÃ©s + 4 fake DOCX archivÃ©s
- [x] **RÃ©sultat** : 1832 docs classifiÃ©s, ~7 erreurs rÃ©siduelles (0.4%)

### Phase 5B : Chunking + Classification chunk-level âœ…
- [x] Code modifiÃ© : chunk_image() pour images SCHEMA_DPO
- [x] Code modifiÃ© : url_cache inclut images
- [x] **RÃ©sultat** : 16016 chunks, 1823 docs uniques, 8.8 chunks/doc, 92s

### Phase 6A : Indexation ChromaDB âœ…
- [x] 16044 chunks indexÃ©s (nomic-embed-text, 768 dim)

### Phase 6B : RÃ©sumÃ©s structurÃ©s (Nemo) âœ…
- [x] 1829 rÃ©sumÃ©s gÃ©nÃ©rÃ©s (1823 docs + 6 cleaned entries)
- [x] Filtre navigation corrigÃ© : seuil 2000 chars (ne flag plus les pages riches)
- [x] 5 pages utiles rÃ©cupÃ©rÃ©es (FICOBA, Guide sÃ©curitÃ©, Fiches IA, FNAEG, Guide auto-Ã©valuation IA)
- [x] 0 erreurs, 0 nav skip restant

### Phase 6C : Nettoyage post-rÃ©sumÃ©s âœ…
- [x] Analyse contenu propre des 11 pages nav â†’ 5 faux positifs rÃ©cupÃ©rÃ©s
- [x] 6 vrais nav purgÃ©s de ChromaDB + JSONL
- [x] Fichiers archivÃ©s dans `data/archive/html/`
- [x] Summaries mis Ã  jour (6 entries `cleaned: true`)
- **RÃ©sultat** : 16044 chunks, 1823 docs, 1829 summaries, 0 erreur

---

## ğŸ“Š DONNÃ‰ES BRUTES â€” Analyse doublons (2026-02-09)

```
HTML fichier brut identique    :   38/2568 ( 1.5%)  â† URLs trÃ¨s proches
HTML region-content identique  : 1268/2568 (49.4%)  â† pages CNIL renommÃ©es/redirect
PDF  fichier identique         :  541/1026 (52.7%)  â† mÃªme PDF sous N URLs
Images fichier identique       :   32/65   (49.2%)  â† mÃªme schÃ©ma sous N URLs
```

**Exemples :** mÃªme page CNIL sous http/https, /tag/cloud vs /tag/Cloud,
pages renommÃ©es mais contenu inchangÃ©, un mÃªme PDF recommandations
tÃ©lÃ©chargÃ© depuis 37 pages diffÃ©rentes.

**Impact sans dÃ©dup** : le RAG retournerait N fois la mÃªme info avec des
scores proches â†’ bruit, tokens gaspillÃ©s, confusion pour l'utilisateur.

---

## ğŸ—ï¸ ARCHITECTURE RAG HIÃ‰RARCHISÃ‰E (vision moyen/long terme)

### Niveau 1 : Documents (macro)
- `document_metadata.json` : classification nature/index par document
- `document_summaries.json` : fiche synthÃ©tique par document (Phase 6B)
- DÃ©duplication : 1 canonical par contenu unique, doublons Ã©liminÃ©s
- **RequÃªte** : "De quoi parle ce corpus ?" â†’ recherche par rÃ©sumÃ©s

### Niveau 2 : Chunks (micro)
- `processed_chunks.jsonl` : chunks structurels classifiÃ©s
- Chaque chunk liÃ© Ã  son document parent (document_id, document_path)
- Metadata riches : nature, index, secteurs, heading, source_url
- **RequÃªte** : "Comment faire une AIPD ?" â†’ recherche vectorielle chunks

### Niveau 3 : Retrieval 2-Ã©tapes
```
Question â†’ Query Qualification (intent + filtres)
        â†’ Ã‰tape 1 : RÃ©sumÃ©s documents (top-K documents pertinents)
        â†’ Ã‰tape 2 : Chunks de ces K documents (top-N chunks)
        â†’ Reranking (similarity Ã— confidence Ã— prioritÃ©)
        â†’ Context building (top-5 chunks + metadata)
        â†’ GÃ©nÃ©ration rÃ©ponse + citations
```

### Anti-doublons au query time (filet de sÃ©curitÃ©)
- MÃªme si la dÃ©dup Phase 4C nettoie le corpus, le retriever doit aussi :
  - Grouper chunks par document_id
  - Ne pas retourner >2 chunks du mÃªme document
  - DÃ©tecter chunks quasi-identiques (similarity > 0.95 entre eux)

---

## ğŸ¯ PLAN EXÃ‰CUTION (ordre)

### Sprint actuel : Pipeline propre
1. [x] IntÃ©grer images dans Phase 5A + 5B (code modifiÃ©)
2. [x] **Phase 4C : dÃ©duplication corpus** âœ… (3702 â†’ 1847, -50.1%)
3. [x] IntÃ©grer Phase 4C dans rebuild_pipeline.py
4. [x] **Pipeline 5Aâ†’5B** âœ… (1832 docs, 16016 chunks)
5. [x] **Phase 6A** âœ… (16044 chunks indexÃ©s ChromaDB)
6. [x] **Phase 6B** âœ… (1829 rÃ©sumÃ©s, 0 erreur)
7. [x] **Phase 6C** âœ… (6 nav purgÃ©s, 5 rÃ©cupÃ©rÃ©s, 16044 chunks finaux)

### Sprint suivant : RAG Engine âœ…
6. [x] `src/rag/bm25_index.py` â€” CRÃ‰Ã‰ : Index BM25 summaries + chunks
7. [x] `src/rag/reranker.py` â€” CRÃ‰Ã‰ : Cross-encoder ms-marco-MiniLM-L-6-v2
8. [x] `src/rag/retriever.py` â€” RÃ‰Ã‰CRIT : Hybrid BM25+Semantic+RRF+Summary pre-filter
9. [x] `src/rag/context_builder.py` â€” MAJ : Nouveaux prompts + reverse repacking
10. [x] `src/rag/pipeline.py` â€” MAJ : Reranker intÃ©grÃ©, phases 1â†’5, create_pipeline factory
11. [x] `src/rag/__init__.py` â€” MAJ : 16 exports (BM25, Reranker, etc.)
12. [x] `configs/config.yaml` â€” MAJ : Params RAG hybride + reranker
13. [ ] `test_rag.py` â€” Validation questions DPO types

### Sprint Streamlit : Interface â³
14. [x] `app.py` â€” MAJ : toggles hybrid/reranker/validation, slider dÃ©fauts corrigÃ©s
15. [ ] Test Streamlit end-to-end
16. [ ] Historique conversation
17. [ ] Export conversations

### Sprint QualitÃ© (optionnel)
18. [ ] Hybrid search fine-tuning (Î± BM25, RRF k)
19. [ ] Query expansion (synonymes juridiques RGPD)
20. [ ] Evaluation set (50-100 questions manuelles)
21. [ ] Fine-tuning embeddings vocabulaire RGPD

---

## ğŸ“ RÃ¨gles mÃ©tier DPO

```python
# 1. CNIL prÃ©vaut TOUJOURS sur les docs entreprise
# 2. Jamais inventer â€” si pas de source, dire "je ne sais pas"
# 3. Citations traÃ§ables obligatoires (URL source)
# 4. 100% local (pas de fuite donnÃ©es)
```

# 3. VÃ©rifier index
python -c "import chromadb; client = chromadb.PersistentClient(path='data/chroma_db'); col = client.get_collection('rag_dpo_chunks'); print(f'Chunks indexÃ©s: {col.count()}')"
```

**DurÃ©e estimÃ©e** : ~18 minutes (35 900 chunks)

**Output** : `data/chroma_db/` (base vectorielle)

---

### [ ] 5. Tests de validation
**Tests Ã  rÃ©aliser** :

```python
# Test 1 : Query simple
results = collection.query(
    query_texts=["Comment faire une AIPD ?"],
    n_results=5
)
# â†’ Doit retourner des chunks pertinents

# Test 2 : Filtre par nature
results = collection.query(
    query_texts=["Comment faire une AIPD ?"],
    n_results=5,
    where={"chunk_nature": "GUIDE"}
)
# â†’ Doit retourner UNIQUEMENT des GUIDE

# Test 3 : Filtre par source
results = collection.query(
    query_texts=["Comment faire une AIPD ?"],
    n_results=5,
    where={"source": "CNIL"}
)
# â†’ Doit retourner UNIQUEMENT des chunks CNIL

**MVP fonctionnel** = Sprint 1 + Sprint 3 (~5h dev)

**Encodage** : UTF-8 partout (requirement critique)

---

## ğŸ Ã‰tat actuel (2026-02-05)

### Infrastructure âœ…
- âœ… 56,328 chunks indexÃ©s ChromaDB
- âœ… Ollama embeddings (768 dims)
- âœ… Modes reset/append/update opÃ©rationnels
- âœ… VÃ©rification --verify-only fonctionnelle
- âœ… StratÃ©gie dÃ©duplication documents testÃ©e

### Prochaine action â†’ **Sprint 1 : RAG Basique**

---

## ğŸ“Š Audit Ã‰valuation Q&A (2026-02-10)

### Contexte
GPT a gÃ©nÃ©rÃ© 18 questions d'Ã©valuation couvrant 7 catÃ©gories (dÃ©finitions, obligations, recommandations CNIL, cas pratiques DPO, piÃ¨ges anti-hallucination, robustesse sÃ©mantique, hors pÃ©rimÃ¨tre). Les rÃ©ponses du RAG ont Ã©tÃ© Ã©valuÃ©es par GPT.

### Diagnostic
- âœ… Safety/Faithfulness : solide (pas d'hallucination grossiÃ¨re, refus hors pÃ©rimÃ¨tre OK)
- âœ… Cloisonnement CNIL respectÃ©
- âŒ Erreur factuelle majeure : critÃ¨res AIPD (confusion parties doc vs critÃ¨res dÃ©clenchement)
- âŒ CV 2 ans : retrieval KO (recommandation opÃ©rationnelle non retrouvÃ©e)
- âŒ Liste AIPD : focus inversÃ© (liste blanche vs noire)
- âš ï¸ Sur-justification gÃ©nÃ©ralisÃ©e (rÃ©ponses trop longues, reformulations)
- âš ï¸ ForÃ§age de grounding (art. 20 affichÃ© pour question sur art. 99)
- âš ï¸ "Sources insuffisantes" sur sujets bien documentÃ©s

### Actions rÃ©alisÃ©es
- [x] CrÃ©Ã© `eval/qa_dataset.json` : 18 questions avec must_include/must_not_include/expected_answer
- [x] CrÃ©Ã© `eval/run_eval.py` : scoring auto sur 4 axes (correctness, faithfulness, conciseness, sources)
- [x] AmÃ©liorÃ© prompt system v2 dans `context_builder.py` :
  - Ajout section CONCISION (2-4 phrases d'abord)
  - RÃ¨gle 5 : anti-forÃ§age grounding (ne pas citer source non pertinente)
  - Interdiction "En conclusion" / reformulation finale
  - Interdiction citation source sans rapport avec la question
  - User prompt : consigne concise, anti-forÃ§age explicite
- [x] Baseline Ã©valuation : 85.5% global, 100% faithfulness, 99.4% conciseness, 65% answer_correctness
- [x] Diagnostic retrieval : q05/q09/q11 â€” chunks existent dans ChromaDB mais pas dans top-50
- [x] CrÃ©Ã© `src/rag/query_expander.py` : LLM multi-query (3 reformulations + originale)
- [x] ModifiÃ© `src/rag/retriever.py` : boucle multi-query avec RRF fusion, distance prÃ©servÃ©e
- [x] ModifiÃ© `src/rag/pipeline.py` : QueryExpander wired, rerank_candidates 30â†’50, rerank_top_k 8â†’10
- [x] ModifiÃ© `configs/config.yaml` : query expansion config, relevance_threshold 0.30â†’0.35
- [x] **Ã‰val v2 (query expansion)** : 88.6% global (+3.1%), 73% correctness (+8.1%)
  - 6 questions amÃ©liorÃ©es (q06 +50%, q09 +50%, q18 +50%, q11 +33%, q08 +17%, q05 +16%)
  - 2 rÃ©gressions (q04 -40%, q03 -25%)
  - Temps Ã—2.1 (6.3s â†’ 13.2s)

### RÃ©sultats Ã©valuation

| Version | Global | Correctness | Faithfulness | Conciseness | Sources | Temps |
|---------|--------|-------------|--------------|-------------|---------|-------|
| Baseline (prompt v2) | 85.5% | 65.0% | 100% | 99.4% | 97.2% | 6.3s |
| + Query Expansion | 88.6% | 73.1% | 100% | 97.8% | 97.2% | 13.2s |
| + Eval Fixes (v3) | 91.7% | 80.0% | 100% | 98.0% | 97.2% | 8.2s |
| + bge-reranker-v2-m3 (v5) | 91.2% | 80.0% | 100% | 98.0% | 97.0% | 17.0s |

#### DÃ©tail v3â†’v5 (bge-reranker) :
- ğŸŸ¢ q05 AIPD critÃ¨res : 70%â†’100% (+30%) â€” reranker multilingue retrouve donnÃ©es sensibles/grande Ã©chelle/surveillance
- ğŸŸ¢ q08 Droits personnes : 93%â†’100% (+7%) â€” portabilitÃ© retrouvÃ©e
- ğŸ”´ q03 RT vs ST : 100%â†’80% (-20%) â€” non-dÃ©terminisme LLM (manque finalitÃ©s/instructions)
- ğŸ”´ q18 Contourner CNIL : 100%â†’79% (-21%) â€” non-dÃ©terminisme LLM (manque sanction)
- = q09/q10/q11 inchangÃ©s (60%/73%/73%) â€” problÃ¨me retrieval upstream, pas reranker

### Ã€ faire
- [ ] Investiguer rÃ©gression q04 (AIPD obligatoire : 80% â†’ 40%) â€” expansion noie les bons chunks
- [ ] Investiguer q10 (vidÃ©osurveillance : dit FAUX que intÃ©rÃªt lÃ©gitime impossible) â€” chunks manquants
- [ ] ComplÃ©ter rÃ©sumÃ©s documents (36% â†’ 100%) pour amÃ©liorer summary pre-filter
- [ ] Investiguer q15 (Ã©tude impact) : "risque Ã©levÃ©" DANS la rÃ©ponse mais pas scored â€” bug eval ?
- [ ] Augmenter `summary_prefilter_k` de 20 â†’ 40 (surface plus de docs candidats)
- [ ] Re-chunking ciblÃ© guides opÃ©rationnels CNIL (recrutement, vidÃ©osurveillance, RH)
